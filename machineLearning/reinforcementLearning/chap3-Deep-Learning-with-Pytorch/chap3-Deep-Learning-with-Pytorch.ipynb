{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap3 Deep Learning with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The creation of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [2.1019e-44, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor(3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor([2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca = a.to('cuda')\n",
    "ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1.0, 1.0], requires_grad = True)\n",
    "v2 = torch.tensor([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum = v1 + v2\n",
    "v_res = (v_sum * 2).sum()\n",
    "v_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.is_leaf, v2.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.is_leaf, v_res.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res.backward()\n",
    "v1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2877,  0.4303, -0.6507,  0.3688,  0.3207], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Linear(2, 5)\n",
    "v = torch.FloatTensor([1, 2])\n",
    "l(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): Dropout(p=0.3, inplace=False)\n",
       "  (6): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0966, 0.1523, 0.0966, 0.0881, 0.0966, 0.1048, 0.0763, 0.0966, 0.0966,\n",
       "         0.0956]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(torch.FloatTensor([[1, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
    "        super(OurModule, self).__init__()\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, num_classes),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurModule(\n",
      "  (pipe): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "tensor([[0.3256, 0.3256, 0.3488]], grad_fn=<SoftmaxBackward0>)\n",
      "Data from cuda: tensor([[0.3256, 0.3256, 0.3488]], device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net = OurModule(num_inputs=2, num_classes=3)\n",
    "v = torch.FloatTensor([[2, 3]])\n",
    "out = net(v)\n",
    "print(net)\n",
    "print(out)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Data from cuda: %s\" % out.to('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "funcs = {\"sim\" : math.sin, \"cos\" : math.cos, \"tan\" : math.tan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for angle in range(-360, 360):\n",
    "    angle_rad = angle * math.pi / 180\n",
    "    for name, fun in funcs.items():\n",
    "        val = fun(angle_rad)\n",
    "        writer.add_scalar(name, val, angle)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - GAN on Atari images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Preprocessing of input numpy array:\n",
    "    1. resize image into predefined size\n",
    "    2. move color channel axis to a first place\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        super(InputWrapper, self).__init__(*args)\n",
    "        assert isinstance(self.observation_space, gym.spaces.Box)\n",
    "        old_space = self.observation_space\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            self.observation(old_space.low),\n",
    "            self.observation(old_space.high),\n",
    "            dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # resize image\n",
    "        new_obs = cv2.resize(\n",
    "            observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        # transform (210, 160, 3) -> (3, 210, 160)\n",
    "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
    "        return new_obs.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # this pipe converges image into the single number\n",
    "        self.conv_pipe = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape[0], out_channels=DISCR_FILTERS,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS, out_channels=DISCR_FILTERS*2,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS * 2, out_channels=DISCR_FILTERS * 4,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS * 4, out_channels=DISCR_FILTERS * 8,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS * 8, out_channels=1,\n",
    "                      kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv_pipe(x)\n",
    "        return conv_out.view(-1, 1).squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        # pipe deconvolves input vector into (3, 64, 64) image\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=LATENT_VECTOR_SIZE, out_channels=GENER_FILTERS * 8,\n",
    "                               kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 8, out_channels=GENER_FILTERS * 4,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 4, out_channels=GENER_FILTERS * 2,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 2, out_channels=GENER_FILTERS,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(GENER_FILTERS),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS, out_channels=output_shape[0],\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = gym.logger\n",
    "log.set_level(gym.logger.INFO)\n",
    "\n",
    "LATENT_VECTOR_SIZE = 100\n",
    "DISCR_FILTERS = 64\n",
    "GENER_FILTERS = 64\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# dimension input image will be rescaled\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "REPORT_EVERY_ITER = 100\n",
    "SAVE_IMAGE_EVERY_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(envs, batch_size=BATCH_SIZE):\n",
    "    batch = [e.reset() for e in envs]\n",
    "    env_gen = iter(lambda: random.choice(envs), None)\n",
    "\n",
    "    while True:\n",
    "        e = next(env_gen)\n",
    "        obs, reward, is_done, _ = e.step(e.action_space.sample())\n",
    "        if np.mean(obs) > 0.01:\n",
    "            batch.append(obs)\n",
    "        if len(batch) == batch_size:\n",
    "            # Normalising input between -1 to 1\n",
    "            batch_np = np.array(batch, dtype=np.float32) * 2.0 / 255.0 - 1.0\n",
    "            yield torch.tensor(batch_np)\n",
    "            batch.clear()\n",
    "        if is_done:\n",
    "            e.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Making new env: Breakout-v0\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "We're Unable to find the game \"Breakout\". Note: Gym no longer distributes ROMs. If you own a license to use the necessary ROMs for research purposes you can download them via `pip install gym[accept-rom-license]`. Otherwise, you should try importing \"Breakout\" via the command `ale-import-roms`. If you believe this is a mistake perhaps your copy of \"Breakout\" is unsupported. To check if this is the case try providing the environment variable `PYTHONWARNINGS=default::ImportWarning:ale_py.roms`. For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41696\\1817828974.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m envs = [\n\u001b[0;32m      3\u001b[0m     \u001b[0mInputWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Breakout-v0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AirRaid-v0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pong-v0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      6\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41696\\1817828974.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m envs = [\n\u001b[0;32m      3\u001b[0m     \u001b[0mInputWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Breakout-v0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AirRaid-v0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pong-v0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      6\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\rlbook\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(id, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \"\"\"\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0mnames\u001b[0m \u001b[0massociated\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \"\"\"\n",
      "\u001b[1;32m~\\.conda\\envs\\rlbook\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;34m\"\"\"Instantiates an instance of the environment with appropriate kwargs\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentry_point\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             raise error.Error(\n\u001b[0m\u001b[0;32m    130\u001b[0m                 \u001b[1;34mf\"Attempting to make deprecated env {self.id}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                 \u001b[1;34m\"(HINT: is there a newer registered version of this env?)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\rlbook\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mid_requested\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mofficial\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0mID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mentry_point\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mentrypoint\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menvironment\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mreward_threshold\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mreward\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mconsidered\u001b[0m \u001b[0msolved\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mnondeterministic\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0menvironment\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnon\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0meven\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mseeding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mmax_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0msteps\u001b[0m \u001b[0mthat\u001b[0m \u001b[0man\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mconsist\u001b[0m \u001b[0mof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\rlbook\\lib\\site-packages\\gym\\envs\\atari\\environment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, game, mode, difficulty, obs_type, frameskip, repeat_action_probability, full_action_space, render_mode)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# Seed + Load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         self._action_set = (\n",
      "\u001b[1;32m~\\.conda\\envs\\rlbook\\lib\\site-packages\\gym\\envs\\atari\\environment.py\u001b[0m in \u001b[0;36mseed\u001b[1;34m(self, seed)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             raise error.Error(\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[1;34mf'We\\'re Unable to find the game \"{self._game}\". Note: Gym no longer distributes ROMs. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                 \u001b[1;34mf\"If you own a license to use the necessary ROMs for research purposes you can download them \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[1;34mf'via `pip install gym[accept-rom-license]`. Otherwise, you should try importing \"{self._game}\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: We're Unable to find the game \"Breakout\". Note: Gym no longer distributes ROMs. If you own a license to use the necessary ROMs for research purposes you can download them via `pip install gym[accept-rom-license]`. Otherwise, you should try importing \"Breakout\" via the command `ale-import-roms`. If you believe this is a mistake perhaps your copy of \"Breakout\" is unsupported. To check if this is the case try providing the environment variable `PYTHONWARNINGS=default::ImportWarning:ale_py.roms`. For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "envs = [\n",
    "    InputWrapper(gym.make(name))\n",
    "    for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')\n",
    "]\n",
    "input_shape = envs[0].observation_space.shape\n",
    "\n",
    "net_discr = Discriminator(input_shape=input_shape).to(device)\n",
    "net_gener = Generator(output_shape=input_shape).to(device)\n",
    "\n",
    "objective = nn.BCELoss()\n",
    "gen_optimizer = optim.Adam(\n",
    "    params=net_gener.parameters(), lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999))\n",
    "dis_optimizer = optim.Adam(\n",
    "    params=net_discr.parameters(), lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999))\n",
    "writer = SummaryWriter()\n",
    "\n",
    "gen_losses = []\n",
    "dis_losses = []\n",
    "iter_no = 0\n",
    "\n",
    "true_labels_v = torch.ones(BATCH_SIZE, device=device)\n",
    "fake_labels_v = torch.zeros(BATCH_SIZE, device=device)\n",
    "\n",
    "for batch_v in iterate_batches(envs):\n",
    "    # fake samples, input is 4D: batch, filters, x, y\n",
    "    gen_input_v = torch.FloatTensor(\n",
    "        BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1)\n",
    "    gen_input_v.normal_(0, 1)\n",
    "    gen_input_v = gen_input_v.to(device)\n",
    "    batch_v = batch_v.to(device)\n",
    "    gen_output_v = net_gener(gen_input_v)\n",
    "\n",
    "    # train discriminator\n",
    "    dis_optimizer.zero_grad()\n",
    "    dis_output_true_v = net_discr(batch_v)\n",
    "    dis_output_fake_v = net_discr(gen_output_v.detach())\n",
    "    dis_loss = objective(dis_output_true_v, true_labels_v) + \\\n",
    "                objective(dis_output_fake_v, fake_labels_v)\n",
    "    dis_loss.backward()\n",
    "    dis_optimizer.step()\n",
    "    dis_losses.append(dis_loss.item())\n",
    "\n",
    "    # train generator\n",
    "    gen_optimizer.zero_grad()\n",
    "    dis_output_v = net_discr(gen_output_v)\n",
    "    gen_loss_v = objective(dis_output_v, true_labels_v)\n",
    "    gen_loss_v.backward()\n",
    "    gen_optimizer.step()\n",
    "    gen_losses.append(gen_loss_v.item())\n",
    "\n",
    "    iter_no += 1\n",
    "    if iter_no % REPORT_EVERY_ITER == 0:\n",
    "        log.info(\"Iter %d: gen_loss=%.3e, dis_loss=%.3e\",\n",
    "                    iter_no, np.mean(gen_losses),\n",
    "                    np.mean(dis_losses))\n",
    "        writer.add_scalar(\n",
    "            \"gen_loss\", np.mean(gen_losses), iter_no)\n",
    "        writer.add_scalar(\n",
    "            \"dis_loss\", np.mean(dis_losses), iter_no)\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "    if iter_no % SAVE_IMAGE_EVERY_ITER == 0:\n",
    "        writer.add_image(\"fake\", vutils.make_grid(\n",
    "            gen_output_v.data[:64], normalize=True), iter_no)\n",
    "        writer.add_image(\"real\", vutils.make_grid(\n",
    "            batch_v.data[:64], normalize=True), iter_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2821483241.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_41696\\2821483241.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import ale-import-roms\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Breakout' from 'ale_py.roms' (C:\\Users\\Administrator\\.conda\\envs\\rlbook\\lib\\site-packages\\ale_py\\roms\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41696\\2751503183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0male_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBreakout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0male_py\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mALEInterface\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0male\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mALEInterface\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadROM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBreakout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ALE/Breakout-v5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Breakout' from 'ale_py.roms' (C:\\Users\\Administrator\\.conda\\envs\\rlbook\\lib\\site-packages\\ale_py\\roms\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from ale_py.roms import Breakout\n",
    "from ale_py import ALEInterface\n",
    "ale = ALEInterface()\n",
    "ale.loadROM(Breakout)\n",
    "env = gym.make('ALE/Breakout-v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "840b33d06dad15330bd2ef19768664747fbb3a678b7c2dc850353c9c723e0d14"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('rlbook')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
