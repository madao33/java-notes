# 面试笔记

总结Java后端相关的重要知识点

# Java基础

## 基础

### Java语言的特点

* 简单易学、有丰富的类库
* 面向对象
* 与平台无关性，主要是JVM虚拟机的支持
* 可靠安全
* 支持多线程

### 你说你用过python/C++这些语言，说一下和Java有什么区别，或者说一下Java有什么缺点

* Java是面向对象的，比较符合人的认知
* Java和C++都是面向对象的，都支持封装、继承和多态
* Java不是通过指针访问内存的，程序的内存自动通过垃圾回收算法回收
* Java单继承，C++支持多重继承，虽然Java不可以多继承，但是接口可以多继承

### 说一下Java的八种基本类型

![image-20220801221127384](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220801221127384.png)

### 讲一下int和Integer的区别

* int是基本数据类型，Integer是int的封装类，是引用类型。int默认值是0，而Integer默认值是null，所以Integer能区分出0和null的情况。一旦java看到null，就知道这个引用还没有指向某个对象，再任何引用使用前，必须为其指定一个对象，否则会报错。
* 基本数据类型在声明时系统会自动给它分配空间，而引用类型声明时只是分配了引用空间， 必须通过实例化开辟数据空间之后才可以赋值。数组对象也是一个引用对象，将一个数组赋值给另 一个数组时只是复制了一个引用，所以通过某一个数组所做的修改在另一个数组中也看的见。
* 虽然定义了boolean这种数据类型，但是只对它提供了非常有限的支持。在Java虚拟机中没有任何供boolean值专用的字节码指令，Java语言表达式所操作的boolean值，在编译之后都使用Java 虚拟机中的int数据类型来代替，而boolean数组将会被编码成Java虚拟机的byte数组，每个元素 boolean元素占8位。这样我们可以得出boolean类型占了单独使用是4个字节，在数组中又是1个字 节。使用int的原因是，对于当下32位的处理器（CPU）来说，一次处理数据是32位（这里不是指的 是32/64位系统，而是指CPU硬件层面），具有高效存取的特点。

## 集合

### 有了解过Java中ArrayList和LinkedList的区别

* Array（数组）是基于索引(index)的数据结构，它使用索引在数组中搜索和读取数据是很快的。 Array获取数据的时间复杂度是O(1),但是要删除数据却是开销很大，因为这需要重排数组中的所有 数据, (因为删除数据以后, 需要把后面所有的数据前移)
* LinkList是一个双链表,在添加和删除元素时具有比ArrayList更好的性能.但在get与set方面弱于 ArrayList.当然,这些对比都是指数据量很大或者操作很频繁。

### TreeMap

TreeMap底层基于红黑树实现，可以保证在log(n)的时间复杂度内完成containsKey、get、put、remove操作。同时因为其由红黑树构成，也就是说明了能够维持内部元素的有序性，关于⽀持内部元素有序性的集合还有LinkedHashMap。 

部分细节：  

1. 红黑树相比于AVL树，牺牲了部分平衡性，以换取删除/插⼊操作时少量的旋转次数，整体来说，性能优于AVL
树，但是做了性能测试，发现优化了的AVL树和红黑树相比差不了太多。  
2. AVL树为了维护严苛的平衡条件，在破坏了平衡之后（插⼊、删除），需要执⾏旋转操作。共分为四种：左单
旋、先左后右旋、右单旋、先右后左旋。  
3. TreeMap内部无扩容的概念，因为使⽤的是树的链式存储结构  
4. ⽀持范围查找，查找最近的元素  
5. 以为内部是按照key进⾏排序的，所以不⽀持key为null  
6. 排序依据，根据存放的对象是否实现Comprable接⼝。若实现了，则依据其⾃定义的compareTo⽅法，否者
需要⾃定义外部比较器（Comparator），若是都未实现，则报错。

### PriorityQueue

优先队列，是0个或者多个元素构成的集合，集合中按照某种排序方式（元素⾃身的权重）进⾏排序，不保证内部
元素整体有序，但是每次弹出的元素的优先级最高/低。 

内部的数据结构是堆，因为堆底层的结构是完全⼆叉树，对于树的存储包含有链式存储或者顺序存储，
PriorityQueue使用的是顺序存储，所以使用的是Object[]数组，然后利用完全⼆叉树的性质，解决⽗⼦节点关系问
题。 

默认实现是小根堆

**实现细节**

1. 未指定初始化容量⼤小，默认为11，感觉对于底层使用数组实现的集合，默认⼤小的规定好要没有啥规律可
    循  
2. 扩容比其他集合多了⼀步，在数组长度 < 64 时，扩容为原先的两倍+2，超过64时，扩容为原先的1.5倍，同
    时做了放溢出处理，⽀持最⼤元素个数Integer.MAX_VALUE;  
3. 删除和插⼊操作均会破坏当前的堆结果，所以每次都需要调用siftUp、siftDown动态调整  
4. 插⼊操作是插⼊当前堆的末尾，调用siftUp，⾃底向上调整  
5. 删除操作弹出堆顶元素，然后将堆最后⼀个元素置于堆顶，调用siftDown，⾃顶向下调整  
6. 同样具有fast-fail机制



### HashMap

#### HashMap概述

1. HashMap 底层是⼀个数组  

2. 数组中每个元素是⼀个单向链表（即，采用拉链法解决哈希冲突）  

  单链表的节点每个节点是 Node<K, V> 类型（⻅下源码）  

3. 同⼀个单链表中所有 Node 的 hash值不⼀定⼀样，但是他们对应的数组下标⼀定⼀样

  数组下标利用哈希函数/哈希算法根据 hash值计算得到的  

4. HashMap 是数组和单链表的结合体  

   * 数组查询效率⾼，但是增删元素效率较低  
   * 单链表在随机增删元素方⾯效率较⾼，但是查询效率较低  
   * HashMap 将⼆者结合起来，充分它们各⾃的优点  

5. HashMap 特点  

   * 无序、不可重复  
   * 无序：因为不⼀定挂在那个单链表上了  

6. 为什么不可重复？通过重写 equals 方法保证的

#### HashMap源码

```java
public class HashMap<K,V> extends AbstractMap<K,V>
    implements Map<K,V>, Cloneable, Serializable {
	/**
     * The default initial capacity - MUST be a power of two.
     */
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

    /**
     * The maximum capacity, used if a higher value is implicitly specified
     * by either of the constructors with arguments.
     * MUST be a power of two <= 1<<30.
     */
    static final int MAXIMUM_CAPACITY = 1 << 30;

    /**
     * The load factor used when none specified in constructor.
     */
    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    /**
     * The bin count threshold for using a tree rather than list for a
     * bin.  Bins are converted to trees when adding an element to a
     * bin with at least this many nodes. The value must be greater
     * than 2 and should be at least 8 to mesh with assumptions in
     * tree removal about conversion back to plain bins upon
     * shrinkage.
     */
    static final int TREEIFY_THRESHOLD = 8;

    /**
     * The bin count threshold for untreeifying a (split) bin during a
     * resize operation. Should be less than TREEIFY_THRESHOLD, and at
     * most 6 to mesh with shrinkage detection under removal.
     */
    static final int UNTREEIFY_THRESHOLD = 6;

    /**
     * The smallest table capacity for which bins may be treeified.
     * (Otherwise the table is resized if too many nodes in a bin.)
     * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts
     * between resizing and treeification thresholds.
     */
    static final int MIN_TREEIFY_CAPACITY = 64;

    /**
     * Basic hash bin node, used for most entries.  (See below for
     * TreeNode subclass, and in LinkedHashMap for its Entry subclass.)
     */
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;

        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
    }
```

* HashMap默认初始化容量：16
  * 必须是2的次幂，主要是为了能够通过位运算获取key的索引位置，提升计算的效率
  * 为了达到散列均匀，以便提高HashMap集合的存取效率
* HashMap默认加载因子：0.75f
  * 数组容量达到 $\frac{3}{4}$ 时，开始扩容
* 扩容操作
  * 扩容的哈希表将拥有两倍的原容量，因为计算元素落在哪个位置的时候是 `(n-1)&hash`，`n`为数组长度，这样计算更加高效
  * 

* JDK 8 之后，对 HashMap 底层数据结构（单链表）进行了改进
  * 如果单链表元素超过8个，则将单链表转变为红黑树，大前提是整个Node数组容量>64；
  * 如果红黑树节点数量小于6时，会将红黑树重新变为单链表

**put()方法**

1. 先将 key, value 封装到 Node 对象中   

2. 底层会调用 key 的 hashCode() 方法得出 hash 值   

   ```java
   static final int hash(Object key) {
           int h;
           return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
   }
   ```

3. 通过哈希函数/哈希算法，将 hash 值转换为数组的下标   

  * 如果下标位置上没有任何元素，就把 Node 添加到这个位置上；  
  * 如果下标位置上有但链表，此时会将当前 Node 中的 key 与链表上每⼀个节点中的 key 进行 equals 比
    较
    * 如果所有的 equals 方法返回都是 false，那么这个新节点 Node 将被添加到链表的末尾；  
    * 如果其中有⼀个 equals 返回了 true，那么链表中对应的这个节点的 value 将会被新节点 Node 的 
      value 覆盖。（保证了不可重复）  

> 1. HashMap 中允许 key 和 value 为 null，但是只能有⼀个（不可重复）
> 2. HashTable 中 key 和 value 都不允许为 null

**get()方法**

1. 先调用 key 的 hashCode() 方法得出 hash 值  
2. 通过哈希函数/哈希算法，将 hash 值转换为数组的下标  
3. 通过数组下标快速定位到数组中的某个位置：  
  * 如果这个位置上什么也没有（没有链表），则返回 null；  
  * 如果这个位置上有单链表，此时会将当前 Node 中的 key 与链表上每⼀个节点中的 key 进⾏ equals 比
    较。   
    * 如果所有的 equals 方法返回都是 false，那么 get 方法返回 null；  
    * 如果其中有⼀个 equals 返回了 true，那么这个节点的 value 便是我们要找的 value，此时 get 方
      法最终返回这个要找的 value。  

> * 放在 HashMap 中 key 的元素（或者放在 HashSet 中的元素）需要同时重写 hashCode() 和 equals() 方
>   法
> * 重写 hashCode() 方法时要达到散列分布均匀
>   * 如果 hashCode() 方法返回⼀个固定的值，那么 HashMap 底层则变成了⼀个单链表；
>   * 如果 hashCode() 方法所有返回的值都不同，此时 HashMap 底层则变成了⼀个数组

# 多线程

## 基础知识

### 为什么使用并发编程

* 可以充分利用CPU的计算能力
* 方便业务拆分，提升应用性能

### 并发编程有什么缺点

* 内存泄露
* 上下文切换
* 线程安全
* 死锁

### 并发编程的三要素

* 原子性：指的是一个或多个操作要么执行成功，要么全部执行失败
* 可见性：一个线程对共享变量的修改，另一个线程能够立刻看到
* 有序性：线程执行的顺序按照代码的先后顺序执行(处理器为了实现指令流水线，可能会对一些执行进行重排序)

### 解决线程安全

* 原子性问题：分多线程之间通过synchronized或使用锁lock
* 缓存导致的可见性问题：synchronized、volatile、LCOK，可以解决可见性问题
* 编译优化的有序性问题：Happens-Before规则

### 并行和并发

* 并发：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是 同时执行。 
* 并行：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。 
* 串行：有n个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不 安全情况，也就不存在临界区的问题。

### 线程和进程区别

* 进程：一个在内存中运行的应用程序。 每个正在系统上运行的程序都是一个进程 
* 线程：进程中的一个执行任务（控制单元）， 它负责在程序里独立执行。

进程与线程的区别 

* 根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位 
* 资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。 
* 包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共 同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。 
* 内存分配：同一进程的线程共享本进程的地址空间和资源，而进程与进程之间的地址空间和资源是相互独立的 
* 影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃有可能导致整个进程都死掉。所以多进程要比多线程健壮。 
* 执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

### 什么是上下文切换

* 多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的 形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于 一次上下文切换。 
* 概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 
* 上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 
* Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。

### 死锁的四个必要条件

* 互斥条件：在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，就只能等 待，直至占有资源的进程用毕释放。 
* 占有且等待条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进 程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。 
* 不可抢占条件：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过 来。 
* 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。（比如一个进程集合，A在 等B，B在等C，C在等A）

### 线程的状态

![image-20220812152510964](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220812152510964.png)

![image-20220812152523915](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220812152523915.png)















## 关于Java多线程的synchronized和ThreadLocal有了解过吗

ThreadLocal[^1]和Synchronized都是为了解决多线程中相同变量的访问冲突问题，只是二者处理问题的思路和角度不同。

### ThreadLocal

ThreadLocal 提供了线程本地的实例。它与普通变量的区别在于，每个使用该变量的线程都会初始化一个完全独立的实例副本。ThreadLocal 变量通常被private static修饰。当一个线程结束时，它所使用的所有 ThreadLocal 相对的实例副本都可被回收。

ThreadLocal 适用于每个线程需要自己独立的实例且该实例需要在多个方法中被使用，也即变量在线程间隔离而在方法或类间共享的场景

![image-20220810161243255](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220810161243255.png)

简单的示例如下：两个线程分表获取了自己线程存放的变量，他们之间变量的获取并不会错乱

```java
public class ThreadLocaDemo {

    private static ThreadLocal<String> localVar = new ThreadLocal<String>();

    static void print(String str) {
        //打印当前线程中本地内存中本地变量的值
        System.out.println(str + " :" + localVar.get());
        //清除本地内存中的本地变量
        localVar.remove();
    }
    public static void main(String[] args) throws InterruptedException {

        new Thread(new Runnable() {
            public void run() {
                ThreadLocaDemo.localVar.set("local_A");
                print("A");
                //打印本地变量
                System.out.println("after remove : " + localVar.get());

            }
        },"A").start();

        Thread.sleep(1000);

        new Thread(new Runnable() {
            public void run() {
                ThreadLocaDemo.localVar.set("local_B");
                print("B");
                System.out.println("after remove : " + localVar.get());
            }
        },"B").start();
    }
}
```

**ThreadLocal源码**

set()方法

* 首先获取当前线程`thread`，并获取thread线程中的`ThreadLocalMap`
* 如果当前线程的`ThreadLocalMap`不为空，直接更行value值，如果`map`为空，示例化`ThreadLocalMap`，并将value值初始化

```java
/**
 * Sets the current thread's copy of this thread-local variable
 * to the specified value.  Most subclasses will have no need to
 * override this method, relying solely on the {@link #initialValue}
 * method to set the values of thread-locals.
 *
 * @param value the value to be stored in the current thread's copy of
 *        this thread-local.
 */
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        map.set(this, value);
    } else {
        createMap(t, value);
    }
}

/**
* Get the map associated with a ThreadLocal. Overridden in
* InheritableThreadLocal.
*
* @param  t the current thread
* @return the map
*/
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
```

上述代码的`ThreadLocalMap`是什么，`CreateMap`又是什么，直接点击查看找到以下代码：

可看出ThreadLocalMap是ThreadLocal的内部静态类，而它的构成主要是用Entry来保存数据 ，而且还是继承的弱引用。在Entry内部使用ThreadLocal作为key，使用我们设置的value作为value

`createMap`是直接调用`ThreadLocal`的构造方法，构造一个新的`ThreadLocalMap`

```java
  static class ThreadLocalMap {
 
        /**
         * The entries in this hash map extend WeakReference, using
         * its main ref field as the key (which is always a
         * ThreadLocal object).  Note that null keys (i.e. entry.get()
         * == null) mean that the key is no longer referenced, so the
         * entry can be expunged from table.  Such entries are referred to
         * as "stale entries" in the code that follows.
         */
        static class Entry extends WeakReference<ThreadLocal<?>> {
            /** The value associated with this ThreadLocal. */
            Object value;
 
            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }
    }

/**
* Create the map associated with a ThreadLocal. Overridden in
* InheritableThreadLocal.
*
* @param t the current thread
* @param firstValue value for the initial entry of the map
*/
void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}

/**
* Construct a new map initially containing (firstKey, firstValue).
* ThreadLocalMaps are constructed lazily, so we only create
* one when we have at least one entry to put in it.
*/
ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
    table = new Entry[INITIAL_CAPACITY];
    int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);
    table[i] = new Entry(firstKey, firstValue);
    size = 1;
    setThreshold(INITIAL_CAPACITY);
}
```

get()方法

* get方法同样和set方法一样，首先需要获取当前线程thread-t， 然后获取当前线程的threadlocals变量(ThreadLocalMap)
* 如果当前theadlocals变量不为空，将当前线程的引用this(ThreadLocal)作为键值获取value
* 如果当前threadlocals变量为空，需要对当前线程的threadlocals变量进行初始化，然后返回初始化值

```java
/**
* Returns the value in the current thread's copy of this
* thread-local variable.  If the variable has no value for the
* current thread, it is first initialized to the value returned
* by an invocation of the {@link #initialValue} method.
*
* @return the current thread's value of this thread-local
*/
public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings("unchecked")
            T result = (T)e.value;
            return result;
        }
    }
    return setInitialValue();
}

/**
* Variant of set() to establish initialValue. Used instead
* of set() in case user has overridden the set() method.
*
* @return the initial value
*/
private T setInitialValue() {
    T value = initialValue();
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        map.set(this, value);
    } else {
        createMap(t, value);
    }
    if (this instanceof TerminatingThreadLocal) {
        TerminatingThreadLocal.register((TerminatingThreadLocal<?>) this);
    }
    return value;
}

/**
* Get the entry associated with key.  This method
* itself handles only the fast path: a direct hit of existing
* key. It otherwise relays to getEntryAfterMiss.  This is
* designed to maximize performance for direct hits, in part
* by making this method readily inlinable.
*
* @param  key the thread local object
* @return the entry associated with key, or null if no such
*/
private Entry getEntry(ThreadLocal<?> key) {
    int i = key.threadLocalHashCode & (table.length - 1);
    Entry e = table[i];
    if (e != null && e.get() == key)
        return e;
    else
        return getEntryAfterMiss(key, i, e);
}
```

 remove方法

该方法就是将`ThreadLocal`对应的值从当前`Thread`中的`ThreadLocalMap`中删除

```java
/**
* Removes the current thread's value for this thread-local
* variable.  If this thread-local variable is subsequently
* {@linkplain #get read} by the current thread, its value will be
* reinitialized by invoking its {@link #initialValue} method,
* unless its value is {@linkplain #set set} by the current thread
* in the interim.  This may result in multiple invocations of the
* {@code initialValue} method in the current thread.
*
* @since 1.5
*/
public void remove() {
    ThreadLocalMap m = getMap(Thread.currentThread());
    if (m != null) {
        m.remove(this);
    }
}
```

> 实际上 ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，弱引用的特点是，如果这个对象只存在弱引用，那么在下一次垃圾回收的时候必然会被清理掉
>
> 所以如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会被清理掉的，这样一来 ThreadLocalMap中使用这个 ThreadLocal 的 key 也会被清理掉。但是，value 是强引用，不会被清理，这样一来就会出现 key 为 null 的 value。
>
> ThreadLocal其实是与线程绑定的一个变量，如此就会出现一个问题：如果没有将ThreadLocal内的变量删除（remove）或替换，它的生命周期将会与线程共存。通常线程池中对线程管理都是采用线程复用的方法，在线程池中线程很难结束甚至于永远不会结束，这将意味着线程持续的时间将不可预测，甚至与JVM的生命周期一致。举个例字，如果ThreadLocal中直接或间接包装了集合类或复杂对象，每次在同一个ThreadLocal中取出对象后，再对内容做操作，那么内部的集合类和复杂对象所占用的空间可能会开始持续膨胀。

ThreadLocal常见使用场景

* 每个线程需要有自己单独的实例
* 实例需要在多个方法中共享，但不希望被多线程共享

例如

* 存储用户Session

  ```java
  private static final ThreadLocal threadSession = new ThreadLocal();
   
      public static Session getSession() throws InfrastructureException {
          Session s = (Session) threadSession.get();
          try {
              if (s == null) {
                  s = getSessionFactory().openSession();
                  threadSession.set(s);
              }
          } catch (HibernateException ex) {
              throw new InfrastructureException(ex);
          }
          return s;
      }
  ```

* 数据跨层传输

### Synchronized

Java中的synchronized，通过使⽤内置锁，来实现对共享变量的同步操作，进⽽解决了对共享变量操作的原⼦性、
保证了其他线程对共享变量的可⻅性、有序性，从⽽确保了并发情况下的线程安全。 
同时synchronized是可重⼊的锁，避免了同⼀个线程重复请求⾃身已经获取的锁时出现死锁问题（请求于保持、不
可剥夺感觉都有体现）

**用法**：普通同步⽅法、静态同步⽅法、同步代码块

**内置锁**

在Java中，每个对象都有⼀把锁，放置于对象头中，⽤于记录当前对象被哪个线程所持有。 
相对于实例数据，对象头属于额外开销，所以被设计的极⼩来提⾼效率（⼀个对象在堆中的分布：对象头、实例数
据、对⻬填充）。 
对象头中的markword更加体现了这⼀点。markword⾮结构化的，这样在不同的锁状态下，能够复⽤相同的bit
位。markword中就有存储锁的信息的部分。

![image-20220810155913925](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220810155913925.png)

Synchronized是Java保留关键字，通过线程等待，牺牲时间来解决访问冲突。依靠JVM的锁机制来实现临界区的函数或者变量的访问中的原子性。在同步机制中，通过对象的锁机制保证同一时间只有一个线程的访问变量，此时被用作锁机制的变量被多个线程共享。

```java
public class SqlConnectionUtil {
    private static SqlPool instance=null;
    public static synchronized SqlConnection getInstance(){
        if(instance==null)
            instance=new SqlPool();
        return instance.getSqlConnection();
    }
```

### ThreadLocal和Synchronized的区别

ThreadLocal<T>其实是与线程绑定的一个变量。ThreadLocal和Synchonized都用于解决多线程并发访问。

但是ThreadLocal与synchronized有本质的区别：

1、Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。

2、Synchronized是利用锁的机制，使变量或代码块在某一时该只能被一个线程访问。而ThreadLocal为每一个线程都提供了变量的副本，使得每个线程在某一时间访问到的并不是同一个对象，这样就隔离了多个线程对数据的数据共享。

而ThreadLoal却正好相反，它用于在多个线程间通信时能够获得数据共享。

> 一句话理解ThreadLocal，threadlocl是作为当前线程中属性ThreadLocalMap集合中的某一个Entry的key值Entry（threadlocl,value），虽然不同的线程之间threadlocal这个key值是一样，但是不同的线程所拥有的ThreadLocalMap是独一无二的，也就是不同的线程间同一个ThreadLocal（key）对应存储的值(value)不一样，从而到达了线程间变量隔离的目的，但是在同一个线程中这个value变量地址是一样的。

## 线程池

Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。在开发过程中，合理地使用线程池能够带来许多好处。 

* 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 
* 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 
* 提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用

ThreadPoolExecutor其实也是JAVA的一个类，我们一般通过Executors工厂类的方法，通过传入 不同的参数，就可以构造出适用于不同应用场景下的ThreadPoolExecutor（线程池）

```java
/**
* Creates a new {@code ThreadPoolExecutor} with the given initial
* parameters and default thread factory and rejected execution handler.
* It may be more convenient to use one of the {@link Executors} factory
* methods instead of this general purpose constructor.
*
* @param corePoolSize the number of threads to keep in the pool, even
*        if they are idle, unless {@code allowCoreThreadTimeOut} is set
* @param maximumPoolSize the maximum number of threads to allow in the
*        pool
* @param keepAliveTime when the number of threads is greater than
*        the core, this is the maximum time that excess idle threads
*        will wait for new tasks before terminating.
* @param unit the time unit for the {@code keepAliveTime} argument
* @param workQueue the queue to use for holding tasks before they are
*        executed.  This queue will hold only the {@code Runnable}
*        tasks submitted by the {@code execute} method.
* @throws IllegalArgumentException if one of the following holds:<br>
*         {@code corePoolSize < 0}<br>
*         {@code keepAliveTime < 0}<br>
*         {@code maximumPoolSize <= 0}<br>
*         {@code maximumPoolSize < corePoolSize}
* @throws NullPointerException if {@code workQueue} is null
*/
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue) {
    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
         Executors.defaultThreadFactory(), defaultHandler);
}
```

相关参数的说明

* corePoolSize 核心线程数量 
* maximumPoolSize 最大线程数量 
* keepAliveTime 线程保持时间，N个时间单位 unit 时间单位（比如秒，分） 
* workQueue 阻塞队列 
* threadFactory 线程工厂 
* handler 线程池拒绝策略





# JVM

## 说一下你对Java虚拟机的理解

### Java内存结构

![](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220802212445262.png)

方法区和对是所有线程共享的内存区域；而java栈、本地方法栈和程序员计数器是运行是线程私有的内存区域。

* Java堆（Heap），是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。
* 方法区（Method Area），方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
* 程序计数器（Program Counter Register）,程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。
* JVM栈（JVM Stacks）,与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。
* 本地方法栈（Native Method Stacks）,本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。

### 类加载机制

JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。 由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。

![image-20220811130946227](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220811130946227.png)

* 类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。
* 加载完成后，Class对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证、准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。
* 最后JVM对类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。 

类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap）、扩展加载器（Extension）、系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader的子类）。从Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM更好的保证了Java平台的安全性，在该机制中，JVM自带的Bootstrap是根加载器，其他的加载器都有且仅有一个父类加载器。类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM不会向Java程序提供对Bootstrap的引用。下面是关于几个类加载器的说明：

![image-20220811131032798](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220811131032798.png)

* Bootstrap：一般用本地代码实现，负责加载JVM基础核心类库（rt.jar）；
* Extension：从java.ext.dirs系统属性所指定的目录中加载类库，它的父加载器是Bootstrap；
* System：又叫应用类加载器，其父类是Extension。它是应用最广泛的类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类，是用户自定义加载器的默认父加载器。

### 垃圾回收算法

如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。下图展示了7种作用于不同分代的收集器，其中用于回收新生代的收集器包括Serial、PraNew、ParallelScavenge，回收老年代的收集器包括Serial Old、Parallel Old、CMS，还有用于回收整个Java堆的G1收集器。不同收集器之间的连线表示它们可以搭配使用。

![image-20220802213622688](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220802213622688.png)

* Serial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效；
* ParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现；
* Parallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程时间/(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景；
* Serial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本；
* Parallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本；
* CMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。
* G1(Garbage First)收集器 (标记-整理算法)： Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。
* ZGC（Z Garbage Collector）是一款由Oracle公司研发的，以低延迟为首要目标的一款垃圾收集器。它是基于动态Region内存布局，（暂时）不设年龄分代，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的收集器。在JDK 11新加入，还在实验阶段，主要特点是：回收TB级内存（最大4T），停顿时间不超过10ms。
  * 优点：低停顿，高吞吐量，ZGC收集过程中额外耗费的内存小。
  * 缺点：浮动垃圾目前使用的非常少，真正普及还是需要写时间的。

**新生代收集器**：Serial、ParNew、Parallel Scavenge

**老年代收集器**：CMS、Serial Old、Parallel Old

**整堆收集器**：G1，ZGC(因为不涉年代不在图中)。

# 数据结构

## 排序算法了解过吗，可以详细介绍一下吗

了解过一点，例如冒泡排序和选择排序

* 冒泡排序：每一轮循环都是和相邻的元素比较，然后一步步的将最小的元素或者最大的元素排在前面，时间复杂度是 $O(n^2)$

* 选择排序：每一趟从待排序的数据元素中选择最小（或最大）的一个元素作为首元素，直到所有元素排完为止。每一趟通过不断地比较交换来使得首元素为当前最小，交换是一个比较耗时间的操作，我们可以通过设置一个值来记录较小元素的下标，循环结束后存储的就是当前最小元素的下标，这时再进行交换就可以了。

  ![](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220802214609664.png)

  ```java
  void Swap(int[] arr, int a, int b)
  {
  	int tmp = arr[a];
  	arr[a] = arr[b];
  	arr[b] = tmp;
  }
   
  void SimpleSelectSort(int[] arr)
  {
  	int min, len = arr.length;
  	for (int i = 0;i < len - 1;i++)
  	{
  		min = i;
  		for (int j = i + 1;j < len;j++)
  		{
  			if (arr[min] > arr[j])
  			{
  				min = j;
  			}
  		}
  		if (min != i)
  		{
  			Swap(arr,min,i);
  		}
  	}
  }
  ```

## 写一下反转链表的代码，伪代码即可

了解的链表反转有两种方法：

* 第一种是**递归**，递归的写法是需要明确两个条件：边界条件和递推关系
  * 先说一下**递推关系**：假设递归的顺序是先调整后面的结点，当前结点的后续结点都已经反转了，只需要反转当前结点和其后继结点的关系，这时候只需要将当前结点的后继结点的后继指向当前结点，即`cur.next.next = cur`，然后将当前结点的后继变为`null`，防止循环链表的出现，然后返回反转之后的头结点
  * **边界条件**则是递归到最后一个节点，同时加上判断链表头结点是否为空的判断
* 另一种就是**双指针**，双指针比起递归来说要更好理解一些
  * 首先设置两个指针`pre, cur`，分别表示前一个结点和当前结点
  * 先设置一个临时变量保存当前结点的后继`Node temp = cur.next`，然后将当前结点的后继指向前一个结点`cur.next = pre`，这样实现了后继关系的反转，然后判断下一个，这时候的`pre = cur; cur = temp`
  * 反转结束之后返回`pre`为反转后链表的头结点

具体的代码如下所示：

```java
public class BaiduInterview {
    /**
     * 递归实现链表反转
     * @param root 链表头结点
     * @return 返回反转后链表的头结点
     */
    public static Node reverseLinkedList(Node root) {
        if (root.next == null || root == null)
            return root;
        Node newroot = reverseLinkedList(root.next);
        root.next.next = root;
        root.next = null;
        return newroot;
    }

    public static Node reverseLinkedList2(Node root) {
        if (root.next == null || root == null)
            return root;
        Node pre = null, cur = root;
        while (cur != null) {
            Node temp = cur.next;
            cur.next = pre;
            pre = cur;
            cur = temp;
        }
        return pre;
    }

    /**
     * 通过数组构建链表
     * @param nums 数组
     * @return head 链表头结点
     */
    public static Node constructLinkedList(int[] nums) {
        Node head = new Node();
        Node cur = head;
        for (int num : nums) {
            Node temp = new Node(num);
            temp.next = null;
            cur.next = temp;
            cur = temp;
        }
        return head.next;
    }

    public static void main(String[] args) {
        int[] nums = new int[]{1, 2, 3, 4, 5};
        Node root = constructLinkedList(nums);
//        Node reversed2 = reverseLinkedList(root);
        Node reversed3 = reverseLinkedList2(root);
    }
}

/**
 * 定义链表结点
 */
class Node{
    public int val;
    public Node next;
    public Node(){};
    public Node(int val) {
        this.val = val;
    }
    public Node(int val, Node next) {
        this.val = val;
        this.next = next;
    }
}
```

## 红黑树

红黑树[^5]，Red-Black Tree 「RBT」是一个自平衡(不是绝对的平衡)的二叉查找树(BST)，树上的每个节点都遵循下面的规则:

1. 每个节点都有红色或黑色
2. 树的根始终是黑色的 (黑土地孕育黑树根， )
3. 没有两个相邻的红色节点（红色节点不能有红色父节点或红色子节点，**并没有说不能出现连续的黑色节点**）
4. 从节点（包括根）到其任何后代NULL节点(叶子结点下方挂的两个空节点，并且认为他们是黑色的)的每条路径都具有相同数量的黑色节点

一棵典型的红黑树如下图所示

![image-20220803220406437](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803220406437.png)

关于红黑树的左旋右旋操作过多，后续再来详细记载，可以先查看这篇文章

[红黑树详解_晓之木初的博客-CSDN博客_红黑树](https://blog.csdn.net/u014454538/article/details/120120216)

# 设计模式

## 有了解过Java的设计模式吗，手写一个单例模式

了解过一些，设计模式（Design Pattern）是前辈们对代码开发经验的总结，是解决特定问题的一系列套路。它
不是语法规定，而是一套用来提高代码可复用性、可维护性、可读性、稳健性以及安全性的解决方案。

单例模式、代理模式、模板方法模式、装饰器模式、工厂模式、责任链模式、观察者模式、原型模
式。

单例模式是一种常用的软件设计模式，在应用这个模式时，单例对象的类必须保证只有一个实例存在，整个系统只能使用一个对象实例。
优点：不会频繁地创建和销毁对象，浪费系统资源。

单例模式有很多种的写法[^2]：

* **饿汉式单例模式**的写法：线程安全

  饿汉式在**类加载**时已经创建好该对象，在程序调用时**直接返回**该单例对象即可，即我们在编码时就已经指明了要马上创建这个对象，**不需要等到被调用时再去创建**。

  关于类加载，涉及到JVM的内容，我们目前可以简单认为在程序启动时，这个单例对象就已经创建好了。

  ![image-20220803141933702](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/leetcode/image-20220803141933702.png)

  ```java
  public class Singleton{
      
      private static final Singleton singleton = new Singleton();
      
      private Singleton(){}
      
      public static Singleton getInstance() {
          return singleton;
      }
  }
  ```

  

* **懒汉式单例模式**的写法：非线程安全

  懒汉式创建对象的方法是在程序使用对象前，先判断该对象是否已经实例化**（判空），**若已实例化直接返回该类对象。，否则则先执行实例化操作。

  ![image-20220803141920683](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803141920683.png)

  ```java
  public class Singleton {
      
      private static Singleton singleton;
      
      private Singleton(){}
      
      public static Singleton getInstance() {
          if (singleton == null) {
              singleton = new Singleton();
          }
          return singleton;
      }
      
  }
  ```

  这个单例模式是较为简单的写法，写完之后，面试官问如果在多线程的任务下，很多线程请求，可能会出现线程不安全的情况，都到达`if(singleton == null)`，可能会有复数个线程创建了不同的实例

  ![image-20220803142100572](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803142100572.png)

  如何解决这个问题，这个时候需要考虑加锁，也就是下面这个方式

* **双检锁单例模式**的写法：线程安全

  一般在懒汉单例非线程的代码上进行修改有两种简便的方式：一种是给对象加锁，一种是给方法加锁

  * **对象上锁**

    ```java
    public static Singleton getInstance() {
        synchronized(Singleton.class){
            if (singleton == null) {
                singleton = new Singleton();
            }
        }
        return singleton;
    }
    ```

  * **方法加锁**

    ```java
    public static synchronized Singleton getInstance() {
        if (singleton == null) {
            singleton = new Singleton();
        }
        return singleton;
    }
    ```

  > * 这样就规避了两个线程同时创建Singleton对象的风险，但是引来另外一个问题：**每次去获取对象都需要先获取锁，并发性能非常地差，极端情况下，可能会出现卡顿现象。**
  > * 接下来要做的就是**优化性能，目标是：**如果没有实例化对象则加锁创建，如果已经实例化了，则不需要加锁，直接获取实例

  直接在方法上加锁的方式被废除掉了，这种方式无论如何都需要先获取锁，所以在对象加锁代码的基础上进行优化

  优化的代码如下：

  ```java
  public static Singleton getInstance() {
      if (singleton == null) {  // 线程A和线程B同时看到singleton = null，如果不为null，则直接返回singleton
          synchronized(Singleton.class) { // 线程A或线程B获得该锁进行初始化
              if (singleton == null) { // 其中一个线程进入该分支，另外一个线程则不会进入该分支
                  singleton = new Singleton();
              }
          }
      }
      return singleton;
  }
  ```

  上面的代码已经完美地解决了并发安全+性能低效问题：

  * 第2行代码，如果singleton不为空，则直接返回对象，不需要获取锁；而如果多个线程发现singleton为空，则进入分支；
  * 第3行代码，多个线程尝试争抢同一个锁，只有一个线程争抢成功，第一个获取到锁的线程会再次判断singleton是否为空，因为singleton有可能已经被之前的线程实例化
  * 其它之后获取到锁的线程在执行到第4行校验代码，发现singleton已经不为空了，则不会再new一个对象，直接返回对象即可
  * 之后所有进入该方法的线程都不会去获取锁，在第一次判断singleton对象时已经不为空了

  上面这段代码已经近似完美了，但是还存在最后一个问题：**指令重排**，这个时候可以使用`volatile`防止指令重排

  创建一个对象，在JVM中会经过三步：

  * 为singleton分配内存空间

  * 初始化singleton对象

  * 将singleton指向分配好的内存空间

  指令重排序是指：**JVM在保证最终结果正确的情况下，可以不按照程序编码的顺序执行语句，尽可能提高程序的性能**

  在这三步中，第2、3步有可能会发生指令重排现象，创建对象的顺序变为1-3-2，会导致多个线程获取对象时，有可能线程A创建对象的过程中，执行了1、3步骤，线程B判断singleton已经不为空，获取到未初始化的singleton对象，就会报NPE异常。文字较为晦涩，可以看流程图：

  ![image-20220803143240854](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803143240854.png)

  使用volatile关键字可以**防止指令重排序**，可以这样理解：**使用volatile关键字修饰的变量，可以保证其指令执行的顺序与程序指明的顺序一致，不会发生顺序变换**，这样在多线程环境下就不会发生NPE异常了

  > volatile还有第二个作用：使用volatile关键字修饰的变量，可以保证其内存可见性，即每一时刻线程读取到该变量的值都是内存中最新的那个值，**线程每次操作该变量都需要先读取该变量。**

  最终的代码如下

  ```java
  public class Singleton {
      
      private static volatile Singleton singleton;
      
      private Singleton(){}
      
      public static Singleton getInstance() {
          if (singleton == null) {  // 线程A和线程B同时看到singleton = null，如果不为null，则直接返回singleton
              synchronized(Singleton.class) { // 线程A或线程B获得该锁进行初始化
                  if (singleton == null) { // 其中一个线程进入该分支，另外一个线程则不会进入该分支
                      singleton = new Singleton();
                  }
              }
          }
          return singleton;
      }
  }
  ```

拓展的方式，**枚举实现**

```java
public enum Singleton {
    INSTANCE;
    
    public void doSomething() {
        System.out.println("这是枚举类型的单例模式！");
    }
}
```

枚举实现的优点：

* 对比饿汉和懒汉式来说，更加简洁
* 不需要做任何额外的操作去保证对象单一性与线程安全性
* 使用枚举可以防止调用者使用**反射、序列化和反序列化**机制强制生成多个单例对象，以此破坏单例模式

> * 单例模式常见的写法有两种：懒汉式、饿汉式
> * 懒汉式：在需要用到对象时才实例化对象，正确的实现方式是：Double Check + Lock，解决了并发安全和性能低下问题
> * 饿汉式：在类加载时已经创建好该单例对象，在获取单例对象时直接返回对象即可，不会存在并发安全和性能问题。
> * 在开发中如果对内存要求非常高，那么使用懒汉式写法，可以在特定时候才创建该对象；
> * 如果对内存要求不高使用饿汉式写法，因为简单不易出错，且没有任何并发安全和性能问题
> * 为了防止多线程环境下，因为指令重排序导致变量报NPE，需要在单例对象上添加volatile关键字防止指令重排序
> * 最优雅的实现方式是使用枚举，其代码精简，没有线程安全问题，且 Enum 类内部防止反射和反序列化时破坏单例。

## 有在项目中用到过这种设计模式吗

在个人网站的开发过程中，每一个页面设置了一个head-img，使用的是枚举的单例模式实现的，在每一篇文章和每一个页面加载的时候创建图片的实例，并获取实例，为了加速访问数据，还将对应图片的路径/链接保存在redis数据库中

# 计算机网络

## http和https的区别

HTTP[^3]：超文本传输协议（HTTP，HyperText Transfer Protocol）是互联网上应用最为广泛的一种网络协议。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。它可以使浏览器更加高效。HTTP 协议是以明文方式发送信息的，如果黑客截取了 Web 浏览器和服务器之间的传输报文，就可以直接获得其中的信息。

HTTPS：是以安全为目标的 HTTP 通道，是 HTTP 的安全版。HTTPS 的安全基础是 SSL。SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。SSL 协议可分为两层：SSL 记录协议（SSL Record Protocol），它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。SSL 握手协议（SSL Handshake Protocol），它建立在 SSL 记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。

![image-20220803144740620](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803144740620.png)

简要概括一下两者的区别就是：

1、HTTPS  协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用。(以前的网易官网是http，而网易邮箱是 https 。)

2、HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 SSL 加密传输协议。

3、HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

4、HTTP 的连接很简单，是无状态的。HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。(无状态的意思是其数据包的发送、传输和接收都是相互独立的。无连接的意思是指通信双方都不长久的维持对方的任何信息。)

## 说一下加密算法，即https如何实现加密传输的

加密方法：SSL采用一种叫作公开秘钥加密的加密处理方式，近代的加密方法中加密算法是公开的，而秘钥是保密的，通过这种方式可以保持加密方法的安全性。

共享秘钥加密：加密和解密使用同一个秘钥的方式，在加密时必须要将秘钥也发给对方，在互联网转发秘钥时，如果通信被监听那么秘钥就可能会落入攻击者之手，同时也失去了加密的意义。

使用两把秘钥的公开秘钥加密：公开秘钥加密使用一堆非对称的秘钥，一把叫做私有秘钥，另一把叫做公开秘钥；发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有秘钥进行解密，利用这种方式，不需要发送用来解密的私有秘钥，也不必担心秘钥被攻击者窃听而盗走；但是他的处理速度相对共享秘钥来说很慢。

HTTPS采用混合加密方式：利用两种加密方式的优点，组合起来进行通信；在交换秘钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享加密方式。

https采用对称加密与非对称加密的混合加密方式

混合加密方式原理：

1. 服务端将非对称加密的公钥发送给客户端；
2. 客户端拿着服务端发来的公钥，对对称加密的key做加密并发给服务端；
3. 服务端拿着自己的私钥对发来的密文解密，从来获取到对称加密的key；
4. 二者利用对称加密的key对需要传输的消息做加解密传输。

# 数据库

## 有用过数据库吗，例如MySQL，可以讲一下MySQL的索引和他的索引引擎吗

官方介绍索引是帮助MySQL高效获取数据的数据结构。更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度。一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往是存储在磁盘上的文件中的（可能存储在单独的索引文件中，也可能和数据一起存储在数据文件中）。我们通常所说的索引，包括聚集索引、覆盖索引、组合索引、前缀索引、唯一索引等，没有特别说明，默认都是使用B+树结构组织（多路搜索树，并不一定是二叉的）的索引[^4]。

### 索引类型

* 主键索引：索引列中的值必须是唯一的，不允许有空值

* 普通索引：MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值。

* 唯一索引：索引列中的值必须是唯一的，但是允许为空值。

* 全文索引：只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。 MyISAM和InnoDB中都可以使用全文索引。

* 空间索引：MySQL在5.7之后的版本支持了空间索引，而且支持OpenGIS几何数据模型。MySQL在空间索引这方面遵循OpenGIS几何数据模型规则。

* 前缀索引：在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定。

* 其他（按照索引列数量分类）

  * 单列索引

  * 组合索引

    组合索引的使用，需要遵循最左前缀匹配原则（最左匹配原则）。一般情况下在条件允许的情况下使用组合索引替代多个单列索引使用。

### 索引的数据结构

#### Hash表

Hash表，在Java中的HashMap，TreeMap就是Hash表结构，以键值对的方式存储数据。我们使用Hash表存储表数据Key可以存储索引列，Value可以存储行记录或者行磁盘地址。Hash表在等值查询时效率很高，时间复杂度为O(1)；但是不支持范围快速查找，范围查找时还是只能通过扫描全表方式。

#### 二叉查找树

![image-20220803151811292](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803151811292.png)

每个节点最多有2个分叉，左子树和右子树数据顺序左小右大。

这个特点就是为了保证每次查找都可以这折半而减少IO次数，但是二叉树就很考验第一个根节点的取值，因为很容易在这个特点下出现我们并发想发生的情况“树不分叉了”，这就很难受很不稳定。

#### 平衡二叉树

平衡二叉树是采用二分法思维，平衡二叉查找树除了具备二叉树的特点，最主要的特征是树的左右两个子树的层级最多相差1。在插入删除数据时通过左旋/右旋操作保持二叉树的平衡，不会出现左子树很高、右子树很矮的情况。

使用平衡二叉查找树查询的性能接近于二分查找法，时间复杂度是 O(log2n)。查询id=6，只需要两次IO。

![image-20220803152915087](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803152915087.png)

就这个特点来看，可能各位会觉得这就很好，可以达到二叉树的理想的情况了。然而依然存在一些问题：

时间复杂度和树高相关。树有多高就需要检索多少次，每个节点的读取，都对应一次磁盘 IO 操作。树的高度就等于每次查询数据时磁盘 IO 操作的次数。磁盘每次寻道时间为10ms，在表数据量大时，查询性能就会很差。（1百万的数据量，log2n约等于20次磁盘IO，时间20*10=0.2s）

平衡二叉树不支持范围查询快速查找，范围查询时需要从根节点多次遍历，查询效率不高。

#### B树：改造二叉树

MySQL的数据是存储在磁盘文件中的，查询处理数据时，需要先把磁盘中的数据加载到内存中，磁盘IO 操作非常耗时，所以我们优化的重点就是尽量减少磁盘 IO 操作。访问二叉树的每个节点就会发生一次IO，如果想要减少磁盘IO操作，就需要尽量降低树的高度。

为了最大化利用一次IO空间，一个简单的想法是在每个节点存储多个元素，在每个节点尽可能多的存储数据。每个节点可以存储1000个索引（16k/16=1000），这样就将二叉树改造成了多叉树，通过增加树的叉树，将树从高瘦变为矮胖。构建1百万条数据，树的高度只需要2层就可以（1000*1000=1百万），也就是说只需要2次磁盘IO就可以查询到数据。磁盘IO次数变少了，查询数据的效率也就提高了。

这种数据结构我们称为B树，B树是一种多叉平衡查找树，如下图主要特点：

![image-20220803155515665](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803155515665.png)

1. B树的节点中存储着多个元素，每个内节点有多个分叉。
2. 节点中的元素包含键值和数据，节点中的键值从大到小排列。也就是说，在所有的节点都储存数据。
3. 父节点当中的元素不会出现在子节点中。
4. 所有的叶子结点都位于同一层，叶节点具有相同的深度，叶节点之间没有指针连接。

在B树中查询数据的例子：

> 假如我们查询值等于10的数据。查询路径磁盘块1->磁盘块2->磁盘块5。
>
> 第一次磁盘IO：将磁盘块1加载到内存中，在内存中从头遍历比较，10<15，走左路，到磁盘寻址磁盘块2。
>
> 第二次磁盘IO：将磁盘块2加载到内存中，在内存中从头遍历比较，7<10，到磁盘中寻址定位到磁盘块5。
>
> 第三次磁盘IO：将磁盘块5加载到内存中，在内存中从头遍历比较，10=10，找到10，取出data，如果data存储的行记录，取出data，查询结束。如果存储的是磁盘地址，还需要根据磁盘地址到磁盘中取出数据，查询终止。
>
> 相比二叉平衡查找树，在整个查找过程中，虽然数据的比较次数并没有明显减少，但是磁盘IO次数会大大减少。同时，由于我们的比较是在内存中进行的，比较的耗时可以忽略不计。B树的高度一般2至3层就能满足大部分的应用场景，所以使用B树构建索引可以很好的提升查询的效率。
>
> ![image-20220803162233851](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803162233851.png)
>
> 虽然B树看来已经很理想了，但是仍然存在许多可以优化的地方：
>
> * B树不支持范围查询的快速查找，你想想这么一个情况如果我们想要查找10和35之间的数据，查找到15之后，需要回到根节点重新遍历查找，需要从根节点进行多次遍历，查询效率有待提高。
> * 如果data存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中可存储的数据量就会变少，树相应就会变高，磁盘IO次数就会变大。

#### B+树：改造B树

B+树，作为B树的升级版，在B树基础上，MySQL在B树的基础上继续改造，使用B+树构建索引。B+树和B树最主要的区别在于**非叶子节点是否存储数据**的问题

- B树：非叶子节点和叶子节点都会存储数据。
- B+树：**只有叶子节点才会存储数据**，非叶子节点至存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。

![image-20220803162526549](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803162526549.png)

> B+树的最底层叶子节点包含了所有的索引项。从图上可以看到，B+树在查找数据的时候，由于数据都存放在最底层的叶子节点上，所以每次查找都需要检索到叶子节点才能查询到数据。所以在需要查询数据的情况下每次的磁盘的IO跟树高有直接的关系，但是从另一方面来说，由于数据都被放到了叶子节点，所以放索引的磁盘块锁存放的索引数量是会跟着增加的，所以相对于B树来说，B+树的树高理论上情况下是比B树要矮的。也存在索引覆盖查询的情况，在索引中数据满足了当前查询语句所需要的全部数据，此时只需要找到索引即可立刻返回，不需要检索到最底层的叶子节点

**等值查询**
假如我们查询值等于9的数据。查询路径磁盘块1->磁盘块2->磁盘块6。

* 第一次磁盘IO：将磁盘块1加载到内存中，在内存中从头遍历比较，9<15，走左路，到磁盘寻址磁盘块2。
* 第二次磁盘IO：将磁盘块2加载到内存中，在内存中从头遍历比较，7<9<12，到磁盘中寻址定位到磁盘块6。
* 第三次磁盘IO：将磁盘块6加载到内存中，在内存中从头遍历比较，在第三个索引中找到9，取出data，如果data存储的行记录，取出data，查询结束。如果存储的是磁盘地址，还需要根据磁盘地址到磁盘中取出数据，查询终止。（这里需要区分的是在InnoDB中Data存储的为行数据，而MyIsam中存储的是磁盘地址。）

![image-20220803162810055](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803162810055.png)

**范围查询**

假如我们想要查找9和26之间的数据。查找路径是磁盘块1->磁盘块2->磁盘块6->磁盘块7。

* 首先查找值等于9的数据，将值等于9的数据缓存到结果集。这一步和前面等值查询流程一样，发生了三次磁盘IO。
* 查找到15之后，底层的叶子节点是一个有序列表，我们从磁盘块6，键值9开始向后遍历筛选所有符合筛选条件的数据。
* 第四次磁盘IO：根据磁盘6后继指针到磁盘中寻址定位到磁盘块7，将磁盘7加载到内存中，在内存中从头遍历比较，9<25<26，9<26<=26，将data缓存到结果集。
* 主键具备唯一性（后面不会有<=26的数据），不需再向后查找，查询终止。将结果集返回给用户。

![image-20220803162902012](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803162902012.png)

**可以看到B+树可以保证等值和范围查询的快速查找，MySQL的索引就采用了B+树的数据结构**

### 索引实现

#### MyIsam索引

以一个简单的user表为例。user表存在两个索引，id列为主键索引，age列为普通索引

```mysql
CREATE TABLE `user`
(
  `id`       int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(20) DEFAULT NULL,
  `age`      int(11)     DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `idx_age` (`age`) USING BTREE
) ENGINE = MyISAM
  AUTO_INCREMENT = 1
  DEFAULT CHARSET = utf8;

```

MyISAM的数据文件和索引文件是分开存储的。MyISAM使用B+树构建索引树时，叶子节点中存储的键值为索引列的值，数据为索引所在行的磁盘地址。

主键索引的B+树如下图所示：

![image-20220803163454024](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803163454024.png)

表user的索引存储在索引文件`user.MYI`中，数据文件存储在数据文件 `user.MYD`中

**主键等值索引**

```mysql
select * from user where id = 28;
```

* 先在主键树中从根节点开始检索，将根节点加载到内存，比较28<75，走左路。（1次磁盘IO）
* 将左子树节点加载到内存中，比较16<28<47，向下检索。（1次磁盘IO）
* 检索到叶节点，将节点加载到内存中遍历，比较16<28，18<28，28=28。查找到值等于30的索引项。（1次磁盘IO）
* 从索引项中获取磁盘地址，然后到数据文件user.MYD中获取对应整行记录。（1次磁盘IO）
* 将记录返给客户端。

**磁盘IO次数：3次索引检索+记录数据检索。**

![image-20220803164712589](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803164712589.png)

**主键返回查询数据**

```mysql
select * from user where id between 28 and 47;
```

* 先在主键树中从根节点开始检索，将根节点加载到内存，比较28<75，走左路。（1次磁盘IO）
* 将左子树节点加载到内存中，比较16<28<47，向下检索。（1次磁盘IO）
* 检索到叶节点，将节点加载到内存中遍历比较16<28，18<28，28=28<47。查找到值等于28的索引项。
* 根据磁盘地址从数据文件中获取行记录缓存到结果集中。（1次磁盘IO）
* 我们的查询语句时范围查找，需要向后遍历底层叶子链表，直至到达最后一个不满足筛选条件。
* 向后遍历底层叶子链表，将下一个节点加载到内存中，遍历比较，28<47=47，根据磁盘地址从数据文件中获取行记录缓存到结果集中。（1次磁盘IO）
* 最后得到两条符合筛选条件，将查询结果集返给客户端。

**磁盘IO次数：4次索引检索+记录数据检索**

![image-20220803165338794](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803165338794.png)

> 在 MyISAM 中,辅助索引和主键索引的结构是一样的，没有任何区别，叶子节点的数据存储的都是行记录的磁盘地址。只是主键索引的键值是唯一的，而辅助索引的键值可以重复。
>
> 查询数据时，由于辅助索引的键值不唯一，可能存在多个拥有相同的记录，所以即使是等值查询，也需要按照范围查询的方式在辅助索引树中检索数据。

#### InnoDB索引

每个InnoDB表都有一个聚簇索引 ，聚簇索引使用B+树构建，叶子节点存储的数据是整行记录。一般情况下，聚簇索引等同于主键索引，当一个表没有创建主键索引时，InnoDB会自动创建一个ROWID字段来构建聚簇索引。InnoDB创建索引的具体规则如下：

* 在表上定义主键PRIMARY KEY，InnoDB将主键索引用作聚簇索引。
* 如果表没有定义主键，InnoDB会选择第一个不为NULL的唯一索引列用作聚簇索引。
* 如果以上两个都没有，InnoDB 会使用一个6 字节长整型的隐式字段 ROWID字段构建聚簇索引。该ROWID字段会在插入新行时自动递增。

这里以user_innodb为例，user_innodb的id列为主键，age列为普通索引。

```mysql
CREATE TABLE `user_innodb`
(
  `id`       int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(20) DEFAULT NULL,
  `age`      int(11)     DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `idx_age` (`age`) USING BTREE
) ENGINE = InnoDB;
```

**InnoDB主键索引**

![image-20220803165717554](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803165717554.png)

**查询等值数据**

```mysql
select * from user_innodb where id = 28;
```

* 先在主键树中从根节点开始检索，将根节点加载到内存，比较28<75，走左路。（1次磁盘IO）
* 将左子树节点加载到内存中，比较16<28<47，向下检索。（1次磁盘IO）
* 检索到叶节点，将节点加载到内存中遍历，比较16<28，18<28，28=28。查找到值等于28的索引项，直接可以获取整行数据。将改记录返回给客户端。（1次磁盘IO）

![image-20220803205600971](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803205600971.png)

**辅助索引**

除聚簇索引之外的所有索引都称为辅助索引，InnoDB的辅助索引只会存储主键值而非磁盘地址。

以表user_innodb的age列为例，age索引的索引结果如下图

![image-20220803205628315](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803205628315.png)

底层叶子节点的按照（age，id）的顺序排序，先按照age列从小到大排序，age列相同时按照id列从小到大排序。

使用辅助索引需要**检索两遍索引**：首先检索辅助索引获得主键，然后使用主键到主索引中检索获得记录。

**辅助索引等值查询的情况**

```mysql
select * from t_user_innodb where age=19;
```

![image-20220803205904722](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803205904722.png)

根据在辅助索引树中获取的主键id，到主键索引树检索数据的过程称为**回表**查询。

**磁盘IO数：辅助索引3次+获取记录回表3次**

**组合索引**

还是以自己创建的一个表为例：表 abc_innodb，id为主键索引，创建了一个联合索引idx_abc(a,b,c)。

```mysql
CREATE TABLE `abc_innodb`
(
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `a`  int(11)     DEFAULT NULL,
  `b`  int(11)     DEFAULT NULL,
  `c`  varchar(10) DEFAULT NULL,
  `d`  varchar(10) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `idx_abc` (`a`, `b`, `c`)
) ENGINE = InnoDB;
```

组合索引的数据结构

![image-20220803210223424](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803210223424.png)

**组合索引的查询过程**

```mysql
select * from abc_innodb where a = 13 and b = 16 and c = 4;
```

![image-20220803210836339](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803210836339.png)

**最左匹配原则**

最左前缀匹配原则和联合索引的索引存储结构和检索方式是有关系的。

在组合索引树中，最底层的叶子节点按照第一列a列从左到右递增排列，但是b列和c列是无序的，b列只有在a列值相等的情况下小范围内递增有序，而c列只能在a，b两列相等的情况下小范围内递增有序。

就像上面的查询，B+树会先比较a列来确定下一步应该搜索的方向，往左还是往右。如果a列相同再比较b列。但是如果查询条件没有a列，B+树就不知道第一步应该从哪个节点查起。

可以说创建的idx_abc(a,b,c)索引，相当于创建了(a)、（a,b）（a,b,c）三个索引。、

**组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询(>、<、between、like)就停止匹配**

**覆盖索引**

覆盖索引并不是说是索引结构，覆盖索引是一种很常用的优化手段。因为在使用辅助索引的时候，我们只可以拿到主键值，相当于获取数据还需要再根据主键查询主键索引再获取到数据。但是试想下这么一种情况，在上面abc_innodb表中的组合索引查询时，如果我只需要abc字段的，那是不是意味着我们查询到组合索引的叶子节点就可以直接返回了，而不需要回表。这种情况就是覆盖索引。

## 可以讲一下如何优化数据库查询吗

### 避免回表

在InnoDB的存储引擎中，使用辅助索引查询的时候，因为辅助索引叶子节点保存的数据不是当前记录的数据而是当前记录的主键索引，索引如果需要获取当前记录完整数据就必然需要根据主键值从主键索引继续查询。这个过程我们成位回表。想想回表必然是会消耗性能影响性能。那如何避免呢？

使用索引覆盖，举个例子：现有User表（id(PK),name(key),sex,address,hobby…）

如果在一个场景下，`select id,name,sex from user where name ='zhangsan';`这个语句在业务上频繁使用到，而user表的其他字段使用频率远低于它，在这种情况下，如果我们在建立 name 字段的索引的时候，不是使用单一索引，而是使用联合索引（name，sex）这样的话再执行这个查询语句是不是根据辅助索引查询到的结果就可以获取当前语句的完整数据。这样就可以有效地避免了回表再获取sex的数据。

这里就是一个典型的使用覆盖索引的优化策略减少回表的情况。

### 联合索引

**联合索引**，在建立索引的时候，尽量在多个单列索引上判断下是否可以使用联合索引。联合索引的使用不仅可以节省空间，还可以更容易的使用到索引覆盖。试想一下，索引的字段越多，是不是更容易满足查询需要返回的数据呢。比如联合索引（a_b_c），是不是等于有了索引：a，a_b，a_b_c三个索引，这样是不是节省了空间，当然节省的空间并不是三倍于（a，a_b，a_b_c）三个索引，因为索引树的数据没变，但是索引data字段的数据确实真实的节省了。

**联合索引的创建原则**，在创建联合索引的时候因该把频繁使用的列、区分度高的列放在前面，频繁使用代表索引利用率高，区分度高代表筛选粒度大，这些都是在索引创建的需要考虑到的优化场景，也可以在常需要作为查询返回的字段上增加到联合索引中，如果在联合索引上增加一个字段而使用到了覆盖索引，那我建议这种情况下使用联合索引。

**联合索引的使用**

考虑当前是否已经存在多个可以合并的单列索引，如果有，那么将当前多个单列索引创建为一个联合索引。
当前索引存在频繁使用作为返回字段的列，这个时候就可以考虑当前列是否可以加入到当前已经存在索引上，使其查询语句可以使用到覆盖索引。

# 框架

## 看你项目中有用到SpringBoot和Mybatis，可以聊一下Spring的IOC和AOP吗

### AOP

AOP（面向切面）是一种编程范式，提供从另一个角度来考虑程序结构以完善面向对象编程（OOP）。
AOP为开发者提供了一种描述横切关注点的机制，并能够自动将横切关注点织入到面向对象的软件系统中，从而实现了横切关注点的模块化。
AOP能够将那些与业务无关，却为业务模块所共同调用的[逻辑或](https://so.csdn.net/so/search?q=逻辑或&spm=1001.2101.3001.7020)责任，例如事务处理、日志管理、权限控制等，封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可操作性和可维护性。

**使用AOP的好处**

- 降低模块的耦合度
- 使系统容易扩展
- 提高代码复用性

**AOP的基本概念**

- 连接点（JoinPoint）：需要在程序中插入横切关注点的点，连接点可能是在类初始化、方法调用、字段调用或处理异常等等。Spring中只支持方法执行连接点。
- 切入点（Pointcut）：一组相关连接点的集合。
- 通知（Advice）：在连接点上执行的行为，增强提供了在AOP中需要在切入点所选择的连接点处进行扩展现有行为的手段。包括前置增强（before advice）、后置增强 (after advice)、环绕增强 （around advice）。
- 切面（Aspect）：通知和切入点的结合。
- 织入（Weaving）：织入是一个过程，是将切面应用到目标对象从而创建出AOP代理对象的过程。
- 代理（Proxy）：通过代理方式来对目标对象应用切面。AOP代理可以用JDK动态代理或CGLIB代理实现。
- 目标对象（Target）：需要被织入关注点的对象。即被代理的对象。

![image-20220803214934226](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803214934226.png)

实现AOP的主要设计模式就是动态代理。

### IOC

IOC（控制反转）就是依赖倒置原则的一种代码设计思路。就是把原先在代码里面需要实现的对象创建、对象之间的依赖，反转给容器来帮忙实现。
Spring IOC容器通过xml,注解等其它方式配置类及类之间的依赖关系，完成了对象的创建和依赖的管理注入。实现IOC的主要设计模式是**工厂模式**

![image-20220803215056912](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803215056912.png)

**使用IOC的好处**

- 集中管理，实现类的可配置和易管理。
- 降低了类与类之间的耦合度

# 开放性问题

## 在百度的业务中，爬取了大量的页面，这些页面无法全部放在内存中，如何优化查找

在面试的时候，只能想到哈希映射或者二叉树索引之类的，或者是数据库索引的B+树的实现方式

面试官最后介绍了一种布隆过滤器算法（站在布隆后面&心脏是最强壮的肌肉）

### 布隆过滤器算法

布隆过滤器（Bloom Filter）[^6]是 1970 年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。**它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难**。

当你往简单数组或列表中插入新数据时，将不会根据插入项的值来确定该插入项的索引值。这意味着新插入项的索引值与数据值之间没有直接关系。这样的话，当你需要在数组或列表中搜索相应值的时候，你必须遍历已有的集合。若集合中存在大量的数据，就会影响数据查找的效率。

针对这个问题，你可以考虑使用哈希表。**利用哈希表你可以通过对 “值” 进行哈希处理来获得该值对应的键或索引值**，然后把该值存放到列表中对应的索引位置。这意味着索引值是由插入项的值所确定的，当你需要判断列表中是否存在该值时，只需要对值进行哈希处理并在相应的索引位置进行搜索即可，这时的搜索速度是非常快的。

根据定义，布隆过滤器可以检查值是 **“可能在集合中”** 还是 **“绝对不在集合中”**。“可能” 表示有一定的概率，也就是说可能存在一定为误判率。那为什么会存在误判呢？下面我们来分析一下具体的原因。

布隆过滤器（Bloom Filter）本质上是由长度为 m 的位向量或位列表（仅包含 0 或 1 位值的列表）组成，最初所有的值均设置为 0，如下图所示。

![image-20220803221423444](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803221423444.png)

为了将数据项添加到布隆过滤器中，我们会提供 K 个不同的哈希函数，并将结果位置上对应位的值置为 “1”。在前面所提到的哈希表中，我们使用的是单个哈希函数，因此只能输出单个索引值。而对于布隆过滤器来说，我们将使用多个哈希函数，这将会产生多个索引值。

![image-20220803221528106](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803221528106.png)

如上图所示，当输入 “semlinker” 时，预设的 3 个哈希函数将输出 2、4、6，我们把相应位置 1。假设另一个输入 ”kakuqo“，哈希函数输出 3、4 和 7。你可能已经注意到，索引位 4 已经被先前的 “semlinker” 标记了。此时，我们已经使用 “semlinker” 和 ”kakuqo“ 两个输入值，填充了位向量。当前位向量的标记状态为：

![image-20220803221601391](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803221601391.png)

当对值进行搜索时，与哈希表类似，我们将使用 3 个哈希函数对 ”搜索的值“ 进行哈希运算，并查看其生成的索引值。假设，当我们搜索 ”fullstack“ 时，3 个哈希函数输出的 3 个索引值分别是 2、3 和 7：

![image-20220803221742464](https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/interview/image-20220803221742464.png)

从上图可以看出，相应的索引位都被置为 1，这意味着我们可以说 ”fullstack“ 可能已经插入到集合中。事实上这是误报的情形，产生的原因是由于哈希碰撞导致的巧合而将不同的元素存储在相同的比特位上。幸运的是，布隆过滤器有一个可预测的误判率（FPP）：
$$
P_{fpp} \approx (1-e^{-\frac{kn}{m}})^k
$$

- n 是已经添加元素的数量；
- k 哈希的次数；
- m 布隆过滤器的长度（如比特数组的大小）；

**当我们搜索一个值的时候，若该值经过 K 个哈希函数运算后的任何一个索引位为 ”0“，那么该值肯定不在集合中。但如果所有哈希索引值均为 ”1“，则只能说该搜索的值可能存在集合中**。

### 应用

在实际工作中，布隆过滤器常见的应用场景如下：

- 网页爬虫对 URL 去重，避免爬取相同的 URL 地址；
- 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱；
- Google Chrome 使用布隆过滤器识别恶意 URL；
- Medium 使用布隆过滤器避免推荐给用户已经读过的文章；
- Google BigTable，Apache HBbase 和 Apache Cassandra 使用布隆过滤器减少对不存在的行和列的查找。 除了上述的应用场景之外，布隆过滤器还有一个应用场景就是解决缓存穿透的问题。所谓的缓存穿透就是服务调用方每次都是查询不在缓存中的数据，这样每次服务调用都会到数据库中进行查询，如果这类请求比较多的话，就会导致数据库压力增大，这样缓存就失去了意义。

利用布隆过滤器我们可以预先把数据查询的主键，比如用户 ID 或文章 ID 缓存到过滤器中。当根据 ID 进行数据查询的时候，我们先判断该 ID 是否存在，若存在的话，则进行下一步处理。若不存在的话，直接返回，这样就不会触发后续的数据库查询。需要注意的是缓存穿透不能完全解决，我们只能将其控制在一个可以容忍的范围内。

### 实战

可以创建一个Maven项目，在pom文件中引入以下坐标

```xml
<dependency>
   <groupId>com.google.guava</groupId>
   <artifactId>guava</artifactId>
   <version>28.0-jre</version>
</dependency>
```

然后创建一个测试代码，初始化一百万条数据到过滤器中，然后在原有的基础上增加一万条数据，并且判断这些数据是否存在布隆过滤器中

```java
import com.google.common.base.Charsets;
import com.google.common.hash.BloomFilter;
import com.google.common.hash.Funnels;

public class BloomFilterDemo {
    public static void main(String[] args) {
        int total = 1000000; // 总数量
        BloomFilter<CharSequence> bf = 
          BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), total);
        // 初始化 1000000 条数据到过滤器中
        for (int i = 0; i < total; i++) {
            bf.put("" + i);
        }
        // 判断值是否存在过滤器中
        int count = 0;
        for (int i = 0; i < total + 10000; i++) {
            if (bf.mightContain("" + i)) {
                count++;
            }
        }
        System.out.println("已匹配数量 " + count);
    }
}
```

得到的结果是

```
已匹配数量 1000309
```

上述结果出现了五宝，误报率比预期多了309个元素
$$
\frac{309}{1000000+10000} \times 100\% \approx 3.059\%
$$

# 参考

[^1]: [Java多线程同步之ThreadLocal与Synchromized](https://blog.csdn.net/u012675150/article/details/104109509?ops_request_misc=&request_id=&biz_id=102&utm_term=java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84synchronized%E5%92%8Cthreadloc&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-104109509.142^v39^pc_rank_v37&spm=1018.2226.3001.4187)
[^2]: [我给面试官讲解了单例模式后，他对我竖起了大拇指！](https://blog.csdn.net/weixin_41949328/article/details/107296517?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165950992516781667817752%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=165950992516781667817752&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~pc_rank_v37-1-107296517-null-null.142^v39^pc_rank_v37&utm_term=java%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%20%E9%9D%A2%E8%AF%95%E5%AE%98%E7%AB%96%E8%B5%B7%E5%A4%A7%E6%8B%87%E6%8C%87&spm=1018.2226.3001.4187)
[^3]: [HTTP 和 HTTPS 的区别（面试常考题）](https://blog.csdn.net/qq_36667170/article/details/121656279)
[^4]: [一文搞懂MySQL索引所有知识点（建议收藏）](https://blog.csdn.net/qq_35190492/article/details/109257302)
[^5]: [红黑树，超强动静图详解，简单易懂 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/79980618)
[^6]: [5 分钟搞懂布隆过滤器，亿级数据过滤算法你值得拥有！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/94433082)







